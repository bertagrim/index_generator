{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25528cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "porter = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')#try with medium, see if I get better results?\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e29fce",
   "metadata": {},
   "source": [
    "## 1. Load info dataframes and split into three (toc, body, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0340537",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'cann_info_pages.csv'\n",
    "df_cann_pages = pd.read_csv(path,index_col=0)\n",
    "df_cann_pages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'cann_info_lines.csv'\n",
    "df_cann_lines = pd.read_csv(path,index_col=0)\n",
    "df_cann_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8000760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cann_pages.section_level_1.fillna(\"No info\", inplace=True)\n",
    "df_cann_lines.section_level_1.fillna(\"No info\", inplace=True)\n",
    "df_cann_pages.section_level_2.fillna(\"No info\", inplace=True)\n",
    "df_cann_lines.section_level_2.fillna(\"No info\", inplace=True)\n",
    "df_cann_pages.section_level_3.fillna(\"No info\", inplace=True)\n",
    "df_cann_lines.section_level_3.fillna(\"No info\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef10fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toc\n",
    "df_cann_lines_toc=df_cann_lines[(df_cann_lines.section_level_1.str.match(\"CONTENTS|Contents|contents|Table of Contents|Table of contents\"))|(df_cann_lines.section_level_2.str.match(\"CONTENTS|Contents|contents|Table of Contents|Table of contents\"))|(df_cann_lines.section_level_3.str.match(\"CONTENTS|Contents|contents|Table of Contents|Table of contents\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d224cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#body (both versions)\n",
    "df_cann_pages_body=df_cann_pages[(df_cann_pages.page_number>=19) & (df_cann_pages.page_number<=340)]\n",
    "df_cann_lines_body=df_cann_lines[(df_cann_lines.page_number>=19) & (df_cann_lines.page_number<=340)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43402570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index\n",
    "df_cann_lines_index=df_cann_lines[(df_cann_lines.section_level_1.str.match(\n",
    "  \"INDEX|index|Index|Subject Index|Name Index|Language Index|Citation Index|General Index|Author Index|Indicies\"))|\n",
    "  (df_cann_lines.section_level_2.str.match(\"INDEX|index|Index|Subject Index|Name Index|Language Index|Citation Index|General Index|Author Index|Indicies\"))|\n",
    "  (df_cann_lines.section_level_3.str.match(\"INDEX|index|Index|Subject Index|Name Index|Language Index|Citation Index|General Index|Author Index|Indicies\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biblio\n",
    "df_cann_pages_biblio=df_cann_pages[\n",
    "  (df_cann_pages.section_level_1.str.match(\"REFERENCES|References|references|Bibliography|bibliography\"))|(df_cann_pages.section_level_2.str.match(\"References|references|Bibliography|bibliography\"))|(df_cann_pages.section_level_3.str.match(\"References|references|Bibliography|bibliography\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cann_lines_toc.reset_index(drop=True, inplace=True)\n",
    "df_cann_pages_body.reset_index(drop=True, inplace=True)\n",
    "df_cann_lines_body.reset_index(drop=True, inplace=True)\n",
    "df_cann_lines_index.reset_index(drop=True, inplace=True)\n",
    "df_cann_pages_biblio.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7916a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cann_lines_index.to_csv(\"cann_lines_index.csv\", encoding = 'utf-8')\n",
    "df_cann_pages_biblio.to_csv(\"cann_pages_biblio.csv\", encoding = 'utf-8')\n",
    "#save lines-index df and pages-biblio df to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746ad53",
   "metadata": {},
   "source": [
    "## 2. Cleaning (toc and body -- index and biblio I do it separately later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbac29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "textbook_words=['thus', 'today', 'nowadays', 'actually', 'section', 'indeed', 'every', 'any', 'some', 'example', 'therefore', 'definition', 'introduction', 'conclusion', 'chapter', 'appendix', 'otherwise', 'thing', 'rather', 'instead', 'like', 'since', 'given', 'case', 'hence', 'iff', 'see', 'beyond', 'below', 'above', 'postscript', 'index', 'ensure', 'generally', 'anything', 'something', 'other']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50deec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_data):\n",
    "    tokens=word_tokenize(text_data)\n",
    "\n",
    "    lowercased=[w.lower() for w in tokens]\n",
    "    \n",
    "    no_punct=[word for word in lowercased if (word.isalpha() or re.match(\"[a-z]+-[a-z]+\", word))]\n",
    "    \n",
    "    no_sw=[w for w in no_punct if w not in stop_words]\n",
    "    \n",
    "    clean_tokens=[lemmatizer.lemmatize(word) for word in no_sw]\n",
    "    \n",
    "    #no_tw=[w for w in clean_tokens if w not in textbook_words]\n",
    "    \n",
    "    #long_words=[w for w in no_tw if len(w)>2]#try it with larger than 1 as well\n",
    "    \n",
    "    return (\" \").join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1feab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cann_lines_body[\"clean_content\"] = df_cann_lines_body[\"content\"].apply(clean_text)\n",
    "df_cann_lines_toc[\"clean_content\"] = df_cann_lines_toc[\"content\"].apply(clean_text)\n",
    "df_cann_pages_body[\"clean_content\"] = df_cann_pages_body[\"content\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cann_lines_body.to_csv(\"cann_lines_body_clean.csv\", encoding = 'utf-8')\n",
    "df_cann_pages_body.to_csv(\"cann_pages_body_clean.csv\", encoding = 'utf-8')\n",
    "df_cann_lines_toc.to_csv(\"cann_lines_toc_clean.csv\", encoding = 'utf-8')\n",
    "#save clean dfs to csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
